{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# import all necessary packages\n",
    "%matplotlib inline\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "import numpy as np\n",
    "import tensorflow as tf\n",
    "\n",
    "from keras.preprocessing.image import ImageDataGenerator\n",
    "from keras.preprocessing import image\n",
    "\n",
    "import keras\n",
    "from keras.models import Sequential, Model, load_model\n",
    "from keras.layers import Dense, Dropout, Activation, Flatten, Input\n",
    "from keras.layers import Conv2D, MaxPooling2D\n",
    "import keras.backend as K\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#gram-matrix similarity vs style feature\n",
    "\n",
    "# get the value (maybe of some selected layers) from the network to compare.\n",
    "# run a picture and a style into the network.\n",
    "# define a few loss functions (to calculate the difference between the picture vs the style from the selected layer), the loss function is the average of these loss function\n",
    "\n",
    "\n",
    "# with the loss function output (the output picture), adjust the value using gradient descent to try minimize the loss against the input photo and the style photo.\n",
    "# (you can kick start this with the noise or the input photo)\n",
    "\n",
    "# run through the output again and again into the same network so that the pixle get \"gradient descent\" to fit between the style and your input.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Adversaial Image Creation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# super resolution network (SR network).\n",
    "\n",
    "# feed the low res image into a SR network then an imageNet (without the softmax layer) to extract the feature) \n",
    "# feed the high res image ito an imageNet only (without the softmax layer),\n",
    "# compare the output and calculate the loss,\n",
    "# use the loss to train the SR network.\n",
    "# repeate the cycle for a bunch of data (low res : high res)\n",
    "\n",
    "\n",
    "# transposed convolutions (strided convolutions)\n",
    "\n",
    "#bcolz array"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
